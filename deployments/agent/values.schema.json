{"$schema":"http://json-schema.org/draft-07/schema#","$ref":"#/$defs/helm-values","$defs":{"helm-values":{"type":"object","properties":{"affinity":{"$ref":"#/$defs/helm-values.affinity"},"clusterMonitorServerWorkerServiceAddr":{"$ref":"#/$defs/helm-values.clusterMonitorServerWorkerServiceAddr"},"componentStatusSender":{"$ref":"#/$defs/helm-values.componentStatusSender"},"enable":{"$ref":"#/$defs/helm-values.enable"},"fullnameOverride":{"$ref":"#/$defs/helm-values.fullnameOverride"},"global":{"$ref":"#/$defs/helm-values.global"},"image":{"$ref":"#/$defs/helm-values.image"},"kubernetesManager":{"$ref":"#/$defs/helm-values.kubernetesManager"},"livenessProbe":{"$ref":"#/$defs/helm-values.livenessProbe"},"logLevel":{"$ref":"#/$defs/helm-values.logLevel"},"nameOverride":{"$ref":"#/$defs/helm-values.nameOverride"},"nodeSelector":{"$ref":"#/$defs/helm-values.nodeSelector"},"podAnnotations":{"$ref":"#/$defs/helm-values.podAnnotations"},"podSecurityContext":{"$ref":"#/$defs/helm-values.podSecurityContext"},"replicaCount":{"$ref":"#/$defs/helm-values.replicaCount"},"resources":{"$ref":"#/$defs/helm-values.resources"},"securityContext":{"$ref":"#/$defs/helm-values.securityContext"},"serviceAccount":{"$ref":"#/$defs/helm-values.serviceAccount"},"tolerations":{"$ref":"#/$defs/helm-values.tolerations"},"version":{"$ref":"#/$defs/helm-values.version"},"volumeMounts":{"$ref":"#/$defs/helm-values.volumeMounts"},"volumes":{"$ref":"#/$defs/helm-values.volumes"}},"additionalProperties":false},"helm-values.affinity":{"description":"A Kubernetes Affinity, if required.\nFor more information, see [Assigning Pods to Nodes](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node).\n\nFor example:\naffinity:\n  nodeAffinity:\n   requiredDuringSchedulingIgnoredDuringExecution:\n     nodeSelectorTerms:\n     - matchExpressions:\n       - key: foo.bar.com/role\n         operator: In\n         values:\n         - master","type":"object"},"helm-values.clusterMonitorServerWorkerServiceAddr":{"description":"The address of the cluster-monitor-server to call worker services.","type":"string","default":"cluster-monitor-server-worker-service-grpc:8082"},"helm-values.componentStatusSender":{"type":"object","properties":{"clusterManagerServerWorkerServiceAddr":{"$ref":"#/$defs/helm-values.componentStatusSender.clusterManagerServerWorkerServiceAddr"},"enable":{"$ref":"#/$defs/helm-values.componentStatusSender.enable"},"initialDelay":{"$ref":"#/$defs/helm-values.componentStatusSender.initialDelay"},"interval":{"$ref":"#/$defs/helm-values.componentStatusSender.interval"},"name":{"$ref":"#/$defs/helm-values.componentStatusSender.name"}},"additionalProperties":false},"helm-values.componentStatusSender.clusterManagerServerWorkerServiceAddr":{"description":"The address of the cluster-manager-server to call worker services.","type":"string","default":"cluster-manager-server-worker-service-grpc:8082"},"helm-values.componentStatusSender.enable":{"description":"The flag to enable sending component status to the cluster-manager-server.","type":"boolean","default":true},"helm-values.componentStatusSender.initialDelay":{"description":"initialDelay is the time to wait before starting the sender.","type":"string","default":"1m"},"helm-values.componentStatusSender.interval":{"description":"The interval time to send the component status.","type":"string","default":"15m"},"helm-values.componentStatusSender.name":{"description":"The name of the component.","type":"string","default":"cluster-monitor-agent"},"helm-values.enable":{"description":"This field can be used as a condition when using it as a dependency. This definition is only here as a placeholder such that it is included in the json schema.","type":"boolean"},"helm-values.fullnameOverride":{"description":"Override the \"cluster-monitor-agent.fullname\" value. This value is used as part of most of the names of the resources created by this Helm chart.","type":"string"},"helm-values.global":{"description":"Global values shared across all (sub)charts","type":"object","properties":{"worker":{"$ref":"#/$defs/helm-values.global.worker"}}},"helm-values.global.worker":{"type":"object","properties":{"controlPlaneAddr":{"$ref":"#/$defs/helm-values.global.worker.controlPlaneAddr"},"registrationKeySecret":{"$ref":"#/$defs/helm-values.global.worker.registrationKeySecret"},"tls":{"$ref":"#/$defs/helm-values.global.worker.tls"}}},"helm-values.global.worker.controlPlaneAddr":{"description":"If specified, use this address for accessing the control-plane. This is necessary when installing LLMariner in a multi-cluster mode. For more information, see [Install across Multiple Clusters](https://llmariner.ai/docs/setup/install/multi_cluster_production/).","type":"string","default":""},"helm-values.global.worker.registrationKeySecret":{"type":"object","properties":{"key":{"$ref":"#/$defs/helm-values.global.worker.registrationKeySecret.key"},"name":{"$ref":"#/$defs/helm-values.global.worker.registrationKeySecret.name"}}},"helm-values.global.worker.registrationKeySecret.key":{"description":"The key name with a registration key set.","type":"string","default":"key"},"helm-values.global.worker.registrationKeySecret.name":{"description":"The secret name. `default-cluster-registration-key` is available when the control-plane and worker-plane are in the same cluster. This Secret is generated by cluster-manager-server as default. For more information, see [Install across Multiple Clusters](https://llmariner.ai/docs/setup/install/multi_cluster_production/).","type":"string","default":"default-cluster-registration-key"},"helm-values.global.worker.tls":{"type":"object","properties":{"enable":{"$ref":"#/$defs/helm-values.global.worker.tls.enable"}}},"helm-values.global.worker.tls.enable":{"description":"The flag to enable TLS access to the control-plane.","type":"boolean","default":false},"helm-values.image":{"type":"object","properties":{"pullPolicy":{"$ref":"#/$defs/helm-values.image.pullPolicy"},"repository":{"$ref":"#/$defs/helm-values.image.repository"}},"additionalProperties":false},"helm-values.image.pullPolicy":{"description":"Kubernetes imagePullPolicy on Deployment.","type":"string","default":"IfNotPresent"},"helm-values.image.repository":{"description":"The container image name.","type":"string","default":"public.ecr.aws/cloudnatix/llmariner/cluster-monitor-agent"},"helm-values.kubernetesManager":{"type":"object","properties":{"enableLeaderElection":{"$ref":"#/$defs/helm-values.kubernetesManager.enableLeaderElection"},"healthBindAddress":{"$ref":"#/$defs/helm-values.kubernetesManager.healthBindAddress"},"metricsBindAddress":{"$ref":"#/$defs/helm-values.kubernetesManager.metricsBindAddress"},"pprofBindAddress":{"$ref":"#/$defs/helm-values.kubernetesManager.pprofBindAddress"}},"additionalProperties":false},"helm-values.kubernetesManager.enableLeaderElection":{"description":"Specify whether to enable the leader election.","type":"boolean","default":false},"helm-values.kubernetesManager.healthBindAddress":{"description":"The bind address for the health probe serving.","type":"string","default":":8081"},"helm-values.kubernetesManager.metricsBindAddress":{"description":"The bind address for the metrics serving.","type":"string","default":":8080"},"helm-values.kubernetesManager.pprofBindAddress":{"description":"The bind address for the pprof serving.","type":"string"},"helm-values.livenessProbe":{"type":"object","properties":{"enabled":{"$ref":"#/$defs/helm-values.livenessProbe.enabled"},"failureThreshold":{"$ref":"#/$defs/helm-values.livenessProbe.failureThreshold"},"initialDelaySeconds":{"$ref":"#/$defs/helm-values.livenessProbe.initialDelaySeconds"},"periodSeconds":{"$ref":"#/$defs/helm-values.livenessProbe.periodSeconds"},"successThreshold":{"$ref":"#/$defs/helm-values.livenessProbe.successThreshold"},"timeoutSeconds":{"$ref":"#/$defs/helm-values.livenessProbe.timeoutSeconds"}},"additionalProperties":false},"helm-values.livenessProbe.enabled":{"description":"Specify whether to enable the liveness probe.","type":"boolean","default":true},"helm-values.livenessProbe.failureThreshold":{"description":"After a probe fails `failureThreshold` times in a row, Kubernetes considers that the overall check has failed: the container is not ready/healthy/live.","type":"number","default":5},"helm-values.livenessProbe.initialDelaySeconds":{"description":"Number of seconds after the container has started before startup, liveness or readiness probes are initiated.","type":"number","default":3},"helm-values.livenessProbe.periodSeconds":{"description":"How often (in seconds) to perform the probe. Default to 10 seconds.","type":"number","default":10},"helm-values.livenessProbe.successThreshold":{"description":"Minimum consecutive successes for the probe to be considered successful after having failed.","type":"number","default":1},"helm-values.livenessProbe.timeoutSeconds":{"description":"Number of seconds after which the probe times out.","type":"number","default":3},"helm-values.logLevel":{"description":"The log level of the inference-manager-engine container.","type":"number","default":0},"helm-values.nameOverride":{"description":"Override the \"cluster-monitor-agent.name\" value, which is used to annotate some of the resources that are created by this Chart (using \"app.kubernetes.io/name\").","type":"string"},"helm-values.nodeSelector":{"description":"The nodeSelector on Pods tells Kubernetes to schedule Pods on the nodes with matching labels. For more information, see [Assigning Pods to Nodes](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/).","type":"object"},"helm-values.podAnnotations":{"description":"Optional additional annotations to add to the Deployment Pods.","type":"object"},"helm-values.podSecurityContext":{"description":"Security Context for the cluster-monitor-agent pod. For more information, see [Configure a Security Context for a Pod or Container](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/).","type":"object","default":{"fsGroup":2000}},"helm-values.replicaCount":{"description":"The number of replicas for the cluster-monitor-agent Deployment.","type":"number","default":1},"helm-values.resources":{"description":"Resources to provide to the cluster-monitor-agent pod. For more information, see [Resource Management for Pods and Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-Containers/).\n\nFor example:\nrequests:\n  cpu: 10m\n  memory: 32Mi","type":"object","default":{"limits":{"cpu":"250m"},"requests":{"cpu":"250m","memory":"500Mi"}}},"helm-values.securityContext":{"description":"Security Context for the cluster-monitor-agent container. For more information, see [Configure a Security Context for a Pod or Container](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/).","type":"object","default":{"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"runAsUser":1000}},"helm-values.serviceAccount":{"type":"object","properties":{"create":{"$ref":"#/$defs/helm-values.serviceAccount.create"},"name":{"$ref":"#/$defs/helm-values.serviceAccount.name"}},"additionalProperties":false},"helm-values.serviceAccount.create":{"description":"Specifies whether a service account should be created.","type":"boolean","default":true},"helm-values.serviceAccount.name":{"description":"The name of the service account to use. If not set and create is true, a name is generated using the fullname template.","type":"string"},"helm-values.tolerations":{"description":"A list of Kubernetes Tolerations, if required.\nFor more information, see [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/).\n\nFor example:\ntolerations:\n- key: foo.bar.com/role\n  operator: Equal\n  value: master\n  effect: NoSchedule","type":"array","items":{}},"helm-values.version":{"description":"Override the container image tag to deploy by setting this variable. If no value is set, the chart's appVersion will be used.","type":"string"},"helm-values.volumeMounts":{"description":"Additional volume mounts to add to the cluster-monitor-agent container. For more information, see [Volumes](https://kubernetes.io/docs/concepts/storage/volumes/).","type":"array","items":{}},"helm-values.volumes":{"description":"Additional volumes to add to the cluster-monitor-agent pod. For more information, see [Volumes](https://kubernetes.io/docs/concepts/storage/volumes/).","type":"array","items":{}}}}
